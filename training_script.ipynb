{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fef04032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# @title 1. Install Dependencies\n",
    "!pip install -q torch transformers datasets accelerate huggingface_hub python-dotenv matplotlib liger-kernel \n",
    "!pip install -q git+https://github.com/KellerJordan/Muon # Install Muon Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40034f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Muon Optimizer enabled.\n",
      "‚úÖ Liger Kernel enabled.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import glob\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from contextlib import nullcontext\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import HfApi, create_repo\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Try to import Muon and Liger, fallback if missing\n",
    "try:\n",
    "    from muon import MuonWithAuxAdam\n",
    "    HAS_MUON = True\n",
    "    print(\"‚úÖ Muon Optimizer enabled.\")\n",
    "except ImportError:\n",
    "    HAS_MUON = False\n",
    "    print(\"‚ö†Ô∏è Muon not found, using AdamW.\")\n",
    "\n",
    "try:\n",
    "    from liger_kernel.transformers import LigerFusedLinearCrossEntropyLoss\n",
    "    HAS_LIGER = True\n",
    "    print(\"‚úÖ Liger Kernel enabled.\")\n",
    "except ImportError:\n",
    "    HAS_LIGER = False\n",
    "    print(\"‚ö†Ô∏è Liger not found, using standard CrossEntropy.\")\n",
    "\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    # --- Architecture ---\n",
    "    dim: int = 384              \n",
    "    n_layers: int = 6\n",
    "    n_heads: int = 6               \n",
    "    n_kv_heads: int = 2\n",
    "    \n",
    "    # --- MoE Config ---\n",
    "    num_experts: int = 8            \n",
    "    num_shared_experts: int = 1\n",
    "    top_k: int = 2\n",
    "    expert_hidden_dim: int = 1024\n",
    "    \n",
    "    # --- MLA Config ---\n",
    "    kv_lora_rank: int = 64         \n",
    "    q_lora_rank: int = 256   \n",
    "    rope_theta: float = 10000.0\n",
    "    norm_eps: float = 1e-6\n",
    "    \n",
    "    # --- Training ---\n",
    "    vocab_size: int = 50257         # GPT-2 Vocab for TinyStories\n",
    "    max_seq_len: int = 512          # Short context\n",
    "    batch_size: int = 32       # Fits 14GB VRAM\n",
    "    gradient_accumulation_steps: int = 2\n",
    "    \n",
    "    # --- Optimization ---\n",
    "    lr_decay_iters: int = 50000     \n",
    "    warmup_iters: int = 1000\n",
    "    max_lr: float = 6e-4            \n",
    "    min_lr: float = 6e-5\n",
    "    weight_decay_optim: float = 0.1\n",
    "    clip: float = 1.0\n",
    "    total_iters: int = 50000\n",
    "    eval_iters: int = 200\n",
    "    save_checkpoint_iter: int = 1000\n",
    "    dropout: float = 0.0\n",
    "    aux_loss_coef: float = 0.01\n",
    "    \n",
    "    # --- System ---\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    use_liger: bool = False # To debug negative loss\n",
    "    dataset: str = \"roneneldan/TinyStories\" \n",
    "    checkpoint_dir: str = \"checkpoints_tinystories\"\n",
    "    #hf_token: str = os.getenv(\"\")\n",
    "    hf_token: str = \"\"\n",
    "    hf_repo_id: str = \"FusionCorp/DeepSeek-V3-TinyStories\"\n",
    "    gradient_checkpointing: bool = False\n",
    "\n",
    "    # Periodic Validation\n",
    "    val_interval: int = 500         # Run validation every 500 steps\n",
    "    val_batches: int = 20           # Number of batches to check during validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da25701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. MODEL DEFINITION\n",
    "# ==========================================\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        var = torch.mean(x ** 2, dim=-1, keepdim=True)\n",
    "        x = x * torch.rsqrt(var + self.eps)\n",
    "        return x * self.weight\n",
    "\n",
    "def apply_rotary_emb(xq, xk, freq_cis):\n",
    "    xq_out = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
    "    xk_out = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
    "    freq_cis = freq_cis[:xq.shape[1]]\n",
    "\n",
    "    freq_cis = freq_cis.view(1, xq.shape[1], 1, -1)\n",
    "    \n",
    "    xq_out = torch.view_as_real(xq_out * freq_cis).flatten(3)\n",
    "    xk_out = torch.view_as_real(xk_out * freq_cis).flatten(3)\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
    "\n",
    "class MLA(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.dim = args.dim\n",
    "        self.n_heads = args.n_heads\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "        self.kv_lora_rank = args.kv_lora_rank\n",
    "        \n",
    "        self.wq = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.w_kv_down = nn.Linear(args.dim, args.kv_lora_rank, bias=False)\n",
    "        self.w_kv_up = nn.Linear(args.kv_lora_rank, 2 * (args.n_heads * self.head_dim), bias=False)\n",
    "        self.wo = nn.Linear(args.n_heads * self.head_dim, args.dim, bias=False)\n",
    "        \n",
    "        self.q_norm = RMSNorm(self.head_dim)\n",
    "        self.k_norm = RMSNorm(self.head_dim)\n",
    "        self.register_buffer(\"freqs_cis\", self.precompute_freqs_cis(args.dim // args.n_heads, args.max_seq_len))\n",
    "\n",
    "    def precompute_freqs_cis(self, dim: int, end: int, theta: float = 10000.0):\n",
    "        freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "        t = torch.arange(end, device=freqs.device)\n",
    "        freqs = torch.outer(t, freqs).float()\n",
    "        freqs_cis = torch.polar(torch.ones_like(freqs), freqs)\n",
    "        return freqs_cis\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        xq = self.wq(x).view(B, T, self.n_heads, self.head_dim)\n",
    "        latent_kv = self.w_kv_down(x)\n",
    "        kv = self.w_kv_up(latent_kv).view(B, T, 2, self.n_heads, self.head_dim)\n",
    "        xk, xv = kv.unbind(2)\n",
    "        \n",
    "        xq, xk = self.q_norm(xq), self.k_norm(xk)\n",
    "        xq, xk = apply_rotary_emb(xq, xk, self.freqs_cis)\n",
    "        \n",
    "        out = F.scaled_dot_product_attention(\n",
    "            xq.transpose(1, 2), xk.transpose(1, 2), xv.transpose(1, 2), is_causal=True\n",
    "        )\n",
    "        return self.wo(out.transpose(1, 2).contiguous().view(B, T, C))\n",
    "\n",
    "class DeepSeekMoE(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.num_experts = args.num_experts\n",
    "        self.top_k = args.top_k\n",
    "        self.num_shared = args.num_shared_experts\n",
    "        self.gate = nn.Linear(args.dim, args.num_experts, bias=False)\n",
    "        \n",
    "        self.shared_experts = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(args.dim, args.expert_hidden_dim, bias=False), \n",
    "                nn.SiLU(), \n",
    "                nn.Linear(args.expert_hidden_dim, args.dim, bias=False)\n",
    "            ) for _ in range(self.num_shared)\n",
    "        ])\n",
    "        self.routed_experts = nn.ModuleList([\n",
    "             nn.Sequential(\n",
    "                nn.Linear(args.dim, args.expert_hidden_dim, bias=False), \n",
    "                nn.SiLU(), \n",
    "                nn.Linear(args.expert_hidden_dim, args.dim, bias=False)\n",
    "            ) for _ in range(self.num_experts)\n",
    "        ])\n",
    "\n",
    "        for expert in self.shared_experts:\n",
    "            expert[2].res_scale = True\n",
    "        \n",
    "        for expert in self.routed_experts:\n",
    "            expert[2].res_scale = True\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        original_shape = x.shape\n",
    "        x_flat = x.view(-1, original_shape[-1])\n",
    "        \n",
    "        # 1. Compute Shared Experts (always active)\n",
    "        shared_out = sum(expert(x_flat) for expert in self.shared_experts)\n",
    "        \n",
    "        # 2. Gating and Top-K\n",
    "        logits = self.gate(x_flat)\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        top_k_weights, top_k_indices = torch.topk(probs, self.top_k, dim=-1)\n",
    "        \n",
    "        # Normalize weights so they sum to 1\n",
    "        top_k_weights = top_k_weights / top_k_weights.sum(dim=-1, keepdim=True)\n",
    "        \n",
    "        # Aux Loss for load balancing\n",
    "        aux_loss = (probs.mean(dim=0) * logits.mean(dim=0)).sum() * self.num_experts\n",
    "        \n",
    "        final_out = torch.zeros_like(x_flat)\n",
    "        \n",
    "        # 3. Process each Expert\n",
    "        for i in range(self.num_experts):\n",
    "            # Check which tokens and which k-slots (0 or 1) use expert i\n",
    "            # mask shape: [num_tokens, top_k]\n",
    "            mask = (top_k_indices == i) #sets mask to true whenever we reach the wanted expert\n",
    "            if not mask.any():\n",
    "                continue\n",
    "            \n",
    "            # We process this expert once for all tokens that need it.\n",
    "            # To handle multiple slots (if a token picks the same expert twice) we iterate through the k-slots.\n",
    "            for k in range(self.top_k):\n",
    "                k_mask = (top_k_indices[:, k] == i)\n",
    "                if k_mask.any():\n",
    "                    # Run expert on the relevant tokens and multiply by routing weight\n",
    "                    expert_input = x_flat[k_mask]\n",
    "                    expert_output = self.routed_experts[i](expert_input)\n",
    "                    \n",
    "                    # Add to final output\n",
    "                    final_out[k_mask] += expert_output * top_k_weights[k_mask, k].unsqueeze(-1)\n",
    "\n",
    "        return (shared_out + final_out).view(*original_shape), aux_loss\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.attn_norm = RMSNorm(args.dim)\n",
    "        self.attn = MLA(args)\n",
    "        self.ffn_norm = RMSNorm(args.dim)\n",
    "        self.moe = DeepSeekMoE(args)\n",
    "        self.dropout = nn.Dropout(args.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x + self.dropout(self.attn(self.attn_norm(x)))\n",
    "        moe_out, aux_loss = self.moe(self.ffn_norm(h))\n",
    "        return h + self.dropout(moe_out), aux_loss\n",
    "\n",
    "class DeepSeekV3(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.embedding = nn.Embedding(args.vocab_size, args.dim)\n",
    "        self.layers = nn.ModuleList([Block(args) for _ in range(args.n_layers)])\n",
    "        self.norm = RMSNorm(args.dim)\n",
    "        self.linear_layer = nn.Linear(args.dim, args.vocab_size, bias=False)\n",
    "        self.embedding.weight = self.linear_layer.weight # Weight tying\n",
    "        self.last_aux_loss = 0.0\n",
    "        \n",
    "        if args.use_liger and HAS_LIGER:\n",
    "            self.le_loss = LigerFusedLinearCrossEntropyLoss()\n",
    "            \n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "\n",
    "        std = 0.02 \n",
    "\n",
    "        # Check for flag\n",
    "        if hasattr(module,'res_scale')  and module.res_scale:\n",
    "            # Scale down by 1/sqrt(2 * n_layers)\n",
    "            std *= (2 * self.args.n_layers) ** -0.5\n",
    "\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=std)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=std)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        x = self.embedding(input_ids)\n",
    "        #total_aux_loss = 0.0\n",
    "\n",
    "        total_aux_loss = torch.tensor(0.0, device=x.device, dtype=x.dtype)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            if self.training and self.args.gradient_checkpointing:\n",
    "                x, aux_loss = torch.utils.checkpoint.checkpoint(layer, x, use_reentrant=True)\n",
    "            else:\n",
    "                x, aux_loss = layer(x)\n",
    "\n",
    "            # trying x = x + 1 instead                \n",
    "            total_aux_loss = total_aux_loss + aux_loss\n",
    "        \n",
    "        x = self.norm(x)\n",
    "        self.last_aux_loss = total_aux_loss\n",
    "        if self.args.use_liger and self.training: return x\n",
    "        return self.linear_layer(x)\n",
    "\n",
    "# ==========================================\n",
    "# 3. DATA PIPELINE\n",
    "# ==========================================\n",
    "def initialize_tokenizer(hf_token=None):\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", token=hf_token)\n",
    "    except:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "    if tokenizer.pad_token is None: tokenizer.pad_token = tokenizer.eos_token\n",
    "    return tokenizer\n",
    "\n",
    "class TinyStoriesStreamDataset(IterableDataset):\n",
    "    def __init__(self, split, tokenizer, seq_len, dataset_name, hf_token=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_len = seq_len\n",
    "        self.dataset = load_dataset(dataset_name, split=\"train\" if split == \"train\" else \"validation\", streaming=True, token=hf_token)\n",
    "\n",
    "    def __iter__(self):\n",
    "        iterator = iter(self.dataset)\n",
    "        buffer = []\n",
    "        while True:\n",
    "            try:\n",
    "                text = next(iterator)['text']\n",
    "                tokens = self.tokenizer.encode(\n",
    "                text,\n",
    "                add_special_tokens=True,\n",
    "                max_length = 1e6,\n",
    "                truncation = False ) # to get rid of the HF warning\n",
    "\n",
    "                tokens.append(self.tokenizer.eos_token_id)\n",
    "\n",
    "                buffer.extend(tokens)\n",
    "                \n",
    "                while len(buffer) >= self.seq_len + 1:\n",
    "                    chunk = buffer[:self.seq_len + 1]\n",
    "                    buffer = buffer[self.seq_len + 1:]\n",
    "                    yield {'input_ids': torch.tensor(chunk[:-1]), 'labels': torch.tensor(chunk[1:])}\n",
    "            except StopIteration:\n",
    "                iterator = iter(self.dataset) # Infinite loop\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f718c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a34d62093fb4cceb764864a9a9b732d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ecbc18ec064b7cb73d52ed8affc7f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbba3374c7024518ba6f9cf396d4e105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd7960ee8b1a41779e093589779cb130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b9493fcd43474ead76e2920069a5ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Device: cuda | Vocab: 50257\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7415e1426e9248e4b827fc7450f07c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Initialization complete. Starting training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 10.9291 | LR: 6.00e-07:   0%|          | 1/50000 [00:20<283:43:07, 20.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 | Loss: 10.9291 | LR: 6.00e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 7.9116 | LR: 6.60e-06:   0%|          | 11/50000 [01:16<81:05:01,  5.84s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10 | Loss: 7.9116 | LR: 6.60e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 7.4044 | LR: 1.26e-05:   0%|          | 21/50000 [02:14<80:14:34,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20 | Loss: 7.4044 | LR: 1.26e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 6.5805 | LR: 1.86e-05:   0%|          | 31/50000 [03:12<80:15:44,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 30 | Loss: 6.5805 | LR: 1.86e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 6.0467 | LR: 2.46e-05:   0%|          | 41/50000 [04:10<80:21:37,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 40 | Loss: 6.0467 | LR: 2.46e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 5.2644 | LR: 3.06e-05:   0%|          | 51/50000 [05:07<80:26:50,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 50 | Loss: 5.2644 | LR: 3.06e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 4.8289 | LR: 3.66e-05:   0%|          | 61/50000 [06:05<80:06:33,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 60 | Loss: 4.8289 | LR: 3.66e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 4.1939 | LR: 4.26e-05:   0%|          | 71/50000 [07:03<80:15:46,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 70 | Loss: 4.1939 | LR: 4.26e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 3.5041 | LR: 4.86e-05:   0%|          | 81/50000 [08:00<80:02:57,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 80 | Loss: 3.5041 | LR: 4.86e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.8142 | LR: 5.46e-05:   0%|          | 91/50000 [08:58<80:07:40,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 90 | Loss: 2.8142 | LR: 5.46e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0313 | LR: 6.06e-05:   0%|          | 101/50000 [09:56<80:15:36,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 | Loss: 2.0313 | LR: 6.06e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4128 | LR: 6.66e-05:   0%|          | 111/50000 [10:53<80:04:27,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 110 | Loss: 1.4128 | LR: 6.66e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3957 | LR: 7.26e-05:   0%|          | 121/50000 [11:51<80:00:17,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 120 | Loss: 0.3957 | LR: 7.26e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: -0.1975 | LR: 7.80e-05:   0%|          | 130/50000 [12:43<79:50:33,  5.76s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-213092099.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;31m# Run it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipython-input-213092099.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maux_loss_coef\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_aux_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0maccum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             )\n\u001b[0;32m--> 625\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 4. TRAINING UTILS\n",
    "# ==========================================\n",
    "def get_lr(it, args):\n",
    "    if it < args.warmup_iters: return args.max_lr * (it + 1) / args.warmup_iters\n",
    "    if it > args.lr_decay_iters: return args.min_lr\n",
    "    decay_ratio = (it - args.warmup_iters) / (args.lr_decay_iters - args.warmup_iters)\n",
    "    return args.min_lr + 0.5 * (args.max_lr - args.min_lr) * (1.0 + math.cos(math.pi * decay_ratio))\n",
    "\n",
    "def find_latest_checkpoint(checkpoint_dir):\n",
    "    if not os.path.exists(checkpoint_dir): os.makedirs(checkpoint_dir, exist_ok=True); return None, 0\n",
    "    files = glob.glob(os.path.join(checkpoint_dir, \"checkpoint_*.pt\"))\n",
    "    if not files: return None, 0\n",
    "    latest = max(files, key=lambda f: int(re.search(r'checkpoint_(\\d+).pt', f).group(1)))\n",
    "    return latest, int(re.search(r'checkpoint_(\\d+).pt', latest).group(1))\n",
    "\n",
    "\n",
    "def log_metrics(path, step, loss, lr):\n",
    "    file_exists = os.path.exists(path)\n",
    "    with open(path, \"a\") as f:\n",
    "        if not file_exists:\n",
    "            f.write(\"step,loss,lr\\n\")\n",
    "        f.write(f\"{step},{loss},{lr}\\n\")\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(model, val_iterator, val_loader, args):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    \n",
    "    # We check 'val_batches' to get a stable average\n",
    "    for _ in range(args.val_batches):\n",
    "        try:\n",
    "            batch = next(val_iterator)\n",
    "        except StopIteration:\n",
    "            # If we hit the end of the val stream, restart it\n",
    "            val_iterator = iter(val_loader)\n",
    "            batch = next(val_iterator)\n",
    "            \n",
    "        idx, targets = batch['input_ids'].to(args.device), batch['labels'].to(args.device)\n",
    "        \n",
    "        with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "            out = model(idx)\n",
    "            # Use standard CE loss for validation\n",
    "            loss = F.cross_entropy(out.view(-1, args.vocab_size), targets.view(-1))\n",
    "            \n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    avg_loss = sum(losses) / len(losses)\n",
    "    model.train() # Switch back to training mode\n",
    "    return avg_loss, val_iterator\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3bd7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training loop\n",
    "\n",
    "def train():\n",
    "    torch.cuda.empty_cache()\n",
    "    import gc\n",
    "    gc.collect()\n",
    "\n",
    "    # Necessary for Muon to work\n",
    "    if not dist.is_initialized():\n",
    "        os.environ['MASTER_ADDR'] = 'localhost'\n",
    "        os.environ['MASTER_PORT'] = '12355'\n",
    "        dist.init_process_group(backend='nccl', rank=0, world_size=1)\n",
    "\n",
    "    args = ModelArgs()\n",
    "\n",
    "    #Saving to HuggingFace\n",
    "    hf_api = HfApi(token=args.hf_token)\n",
    "\n",
    "    if args.hf_repo_id and args.hf_token:\n",
    "        try:\n",
    "            create_repo(args.hf_repo_id, repo_type=\"model\", exist_ok=True, token=args.hf_token)\n",
    "            print(f\" Connected to Hugging Face repo: {args.hf_repo_id}\")\n",
    "        except Exception as e:\n",
    "            print(f\" Could not create/connect to HF repo: {e}\")\n",
    "\n",
    "    csv_name = \"training_log.csv\"\n",
    "    local_csv_path = os.path.join(args.checkpoint_dir, csv_name)\n",
    "\n",
    "    # DOWNLOAD existing log from HF if it exists (for continuity)\n",
    "    if args.hf_repo_id and args.hf_token:\n",
    "        try:\n",
    "            from huggingface_hub import hf_hub_download\n",
    "            hf_hub_download(\n",
    "                repo_id=args.hf_repo_id,\n",
    "                filename=csv_name,\n",
    "                local_dir=args.checkpoint_dir,\n",
    "                token=args.hf_token\n",
    "            )\n",
    "            print(f\" Downloaded existing log from HF. Continuing plots...\")\n",
    "        except Exception:\n",
    "            print(\" Starting a new training log.\")\n",
    "    \n",
    "    tokenizer = initialize_tokenizer(args.hf_token)\n",
    "    print(f\"üöÄ Device: {args.device} | Vocab: {len(tokenizer)}\")\n",
    "\n",
    "    model = DeepSeekV3(args).to(args.device)\n",
    "    \n",
    "    # Optimizer Groups\n",
    "    hidden_params, other_params = [], []\n",
    "    for n, p in model.named_parameters():\n",
    "        if p.requires_grad:\n",
    "            (hidden_params if p.ndim >= 2 and \"norm\" not in n and \"embedding\" not in n else other_params).append(p)\n",
    "\n",
    "    if HAS_MUON:\n",
    "        optimizer = MuonWithAuxAdam([\n",
    "            {'params': hidden_params, 'use_muon': True, 'lr': 0.02, 'weight_decay': 0.01},\n",
    "            {'params': other_params, 'use_muon': False, 'lr': args.max_lr, 'weight_decay': args.weight_decay_optim}\n",
    "        ])\n",
    "    else:\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=args.max_lr, weight_decay=args.weight_decay_optim)\n",
    "\n",
    "    # Resume\n",
    "    ckpt_path, start_step = find_latest_checkpoint(args.checkpoint_dir)\n",
    "    if ckpt_path:\n",
    "        print(f\" Resuming from {start_step}\")\n",
    "        ckpt = torch.load(ckpt_path, map_location=args.device)\n",
    "        model.load_state_dict(ckpt['model'])\n",
    "        optimizer.load_state_dict(ckpt['optimizer'])\n",
    "\n",
    "    # Data (Train)\n",
    "    ds = TinyStoriesStreamDataset('train', tokenizer, args.max_seq_len, args.dataset, args.hf_token)\n",
    "    loader = DataLoader(ds, batch_size=args.batch_size, num_workers=2, pin_memory=True)\n",
    "    iterator = iter(loader)\n",
    "\n",
    "    # --- NEW: Data (Validation) ---\n",
    "    val_ds = TinyStoriesStreamDataset('validation', tokenizer, args.max_seq_len, args.dataset, args.hf_token)\n",
    "    val_loader = DataLoader(val_ds, batch_size=args.batch_size, num_workers=2, pin_memory=True)\n",
    "    val_iterator = iter(val_loader)\n",
    "\n",
    "    # Training Loop\n",
    "    model.train()\n",
    "    pbar = tqdm.tqdm(range(start_step, args.total_iters), initial=start_step)\n",
    "    accum_loss = 0\n",
    "    \n",
    "    print(\" Initialization complete. Starting training loop...\")\n",
    "\n",
    "    for step in range(start_step, args.total_iters):\n",
    "        # LR Schedule\n",
    "        lr = get_lr(step, args)\n",
    "        for g in optimizer.param_groups: \n",
    "            if not g.get('use_muon', False): g['lr'] = lr\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        for micro in range(args.gradient_accumulation_steps):\n",
    "            try: batch = next(iterator)\n",
    "            except: iterator = iter(loader); batch = next(iterator)\n",
    "            \n",
    "            idx, targets = batch['input_ids'].to(args.device), batch['labels'].to(args.device)\n",
    "            \n",
    "            with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "                out = model(idx)\n",
    "                if args.use_liger and HAS_LIGER:\n",
    "                    loss = model.le_loss(model.linear_layer.weight, out.view(-1, args.dim), targets.view(-1))\n",
    "                else:\n",
    "                    loss = F.cross_entropy(out.view(-1, args.vocab_size), targets.view(-1))\n",
    "                \n",
    "                loss = (loss + args.aux_loss_coef * model.last_aux_loss) / args.gradient_accumulation_steps\n",
    "            loss.backward()\n",
    "            accum_loss += loss.item()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # --- NEW: Periodic Validation & Live Sampling ---\n",
    "        # Run every 500 steps (or whatever interval you prefer)\n",
    "        if step % 500 == 0 and step > start_step:\n",
    "            \n",
    "            # 1. Validation Loss\n",
    "            val_loss, val_iterator = estimate_loss(model, val_iterator, val_loader, args)\n",
    "            print(f\"\\nüîç Step {step} | Train Loss: {accum_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "            \n",
    "            # 2. Live Story Generation (Vibe Check)\n",
    "            print(f\" Vibe Check:\")\n",
    "            try:\n",
    "                # Ensure generate_story is defined in your notebook!\n",
    "                generate_story(model, tokenizer, \"Once upon a time\", max_new_tokens=50)\n",
    "            except Exception as e:\n",
    "                print(f\"(Generation skipped: {e})\")\n",
    "            \n",
    "            # IMPORTANT: Put model back in train mode after generation/eval\n",
    "            model.train()\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            print(f\"Step {step} | Loss: {accum_loss:.4f} | LR: {lr:.2e}\")\n",
    "            log_metrics(local_csv_path, step, accum_loss, lr)\n",
    "\n",
    "        if step % 999 == 0:\n",
    "            os.system('nvidia-smi')\n",
    "\n",
    "        pbar.update(1)\n",
    "        pbar.set_description(f\"Loss: {accum_loss:.4f} | LR: {lr:.2e}\")\n",
    "        accum_loss = 0\n",
    "\n",
    "        if step % args.save_checkpoint_iter == 0 and step > start_step:\n",
    "            ckpt_name = f\"checkpoint_{step}.pt\"\n",
    "            path = os.path.join(args.checkpoint_dir, ckpt_name)\n",
    "            \n",
    "            # Save Locally\n",
    "            torch.save({'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'args': args}, path)\n",
    "            print(f\"\\nüíæ Saved locally to {path}\")\n",
    "\n",
    "            # Upload to Hugging Face\n",
    "            if args.hf_repo_id and args.hf_token:\n",
    "                try:\n",
    "                    hf_api.upload_file(\n",
    "                        path_or_fileobj=path,\n",
    "                        path_in_repo=f\"checkpoints/{ckpt_name}\",\n",
    "                        repo_id=args.hf_repo_id\n",
    "                    )\n",
    "                    print(f\"‚òÅÔ∏è Uploaded {ckpt_name} to Hugging Face\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå HF Upload failed: {e}\")\n",
    "\n",
    "            #Upload loss CSV file to HF\n",
    "            if args.hf_repo_id and args.hf_token:\n",
    "                try:\n",
    "                    hf_api.upload_file(\n",
    "                        path_or_fileobj=local_csv_path,\n",
    "                        path_in_repo=csv_name,\n",
    "                        repo_id=args.hf_repo_id\n",
    "                    )\n",
    "                    print(f\"‚òÅÔ∏è Metrics log synced to Hugging Face.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Failed to sync log: {e}\")\n",
    "# Run it\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf68a33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf63a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbab467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c9d6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15ac425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dee3fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f241e60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
